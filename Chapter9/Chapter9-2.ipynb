{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chapter9-2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccwu0918/MathProgramming/blob/main/Chapter9/Chapter9-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7L3_Mk4UIUy"
      },
      "source": [
        "# 第9章 了解深度學習處理時間序列資料的原理(6-10節)\n",
        "接下來要學習RNN與CNN處理時間序列資料的原理。\n",
        "\n",
        "若是在Google Colaboratory的環境下執行程式，請確定已將「硬體加速器」設定為「GPU」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hji1tsGC7OI"
      },
      "source": [
        "#Colaboratory環境的設定\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/MathProgramming/Chapter9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4Sko5mnZ0lR"
      },
      "source": [
        "#函式庫的設定\n",
        "!pip install -q -r ./requirements2.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JozEFkWkTija"
      },
      "source": [
        "#audio_dataset_3class檔案若還沒解壓縮，請將下列的程式碼的註解拿掉\n",
        "#!unzip audio_dataset_3class.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdd6hgiCbpo0"
      },
      "source": [
        "## 9-6 事先整理分類聲音所需的必要資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Cvr93dAoH_"
      },
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "\n",
        "#載入學習專用資料\n",
        "train_data_dir =\"./audio_dataset_3class/train/\"\n",
        "train_df = pd.read_csv(\"audio_dataset_3class/train.csv\", index_col=0)\n",
        "\n",
        "#載入驗證專用資料\n",
        "test_data_dir =\"./audio_dataset_3class/test/\"\n",
        "test_df = pd.read_csv(\"audio_dataset_3class/test.csv\", index_col=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcoit0bXfPF4"
      },
      "source": [
        "#顯示部分用於學習的聲音檔案的名稱與標籤\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbUBHqFyDHXf"
      },
      "source": [
        "#顯示所有標籤值與標籤值的數量\n",
        "train_df[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqBEK-TKDMrY"
      },
      "source": [
        "#載入其中一個大提琴的聲音檔案\n",
        "data, rate = librosa.load(train_data_dir+ train_df[train_df[\"label\"] == \"Cello\"].index[0])\n",
        "\n",
        "#播放載入的檔案\n",
        "ipd.Audio(data = data, rate = rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNWBzq5ON1Ze"
      },
      "source": [
        "#確認載入的大提琴的聲音資料格式\n",
        "print(data.shape)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4AVMs85EELc"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "sampling_rate = 8000\n",
        "#將聲音長度截為3秒\n",
        "audio_duration = 3\n",
        "audio_length = sampling_rate * audio_duration\n",
        "\n",
        "#根據檔案名稱載入聲音檔案\n",
        "def _load_files(data_dir, filenames):\n",
        "  result = []\n",
        "  for i, filename in enumerate(filenames):\n",
        "        file_path = data_dir + filename\n",
        "        data, _ = librosa.core.load(file_path, sr=sampling_rate, res_type='kaiser_fast')\n",
        "        result.append(data)\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def create_audio_dataset(train_df, test_df, train_data_dir, test_data_dir, label_dict):\n",
        "\n",
        "    dim = (audio_length, 1)\n",
        "    train_filenames = train_df.index\n",
        "    test_filenames = test_df.index\n",
        "\n",
        "    #根據檔案名稱載入學習專用資料與驗證專用資料的聲音檔案\n",
        "    _X_train = _load_files(train_data_dir, train_filenames)\n",
        "    _X_test = _load_files(test_data_dir, test_filenames)\n",
        "\n",
        "    #將聲音長度截成audio_length設定的長度(這次設定為3秒)\n",
        "    _X_train = pad_sequences(_X_train, dtype='float32', maxlen=audio_length, padding='pre', truncating='pre', value=0.0).tolist()\n",
        "    _X_test = pad_sequences(_X_test, dtype='float32', maxlen=audio_length, padding='pre', truncating='pre', value=0.0).tolist()\n",
        "\n",
        "    #利用standardScaler將聲音資料的平均值修正為1，變異數修正為1\n",
        "    scaler = StandardScaler()\n",
        "    scaler = scaler.fit(_X_train + _X_test)\n",
        "    _X_train = scaler.transform(_X_train)\n",
        "    _X_test = scaler.transform(_X_test)\n",
        "\n",
        "    X_train = np.empty((len(train_filenames), *dim))\n",
        "    for index, data in enumerate(_X_train):\n",
        "      X_train[index,] = [[d] for d in data]\n",
        "\n",
        "    X_test = np.empty((len(test_filenames), *dim))\n",
        "    for index, data in enumerate(_X_test):\n",
        "      X_test[index,] = [[d] for d in data]\n",
        "\n",
        "\n",
        "    #下列為建立label的部分\n",
        "    labels_train = train_df[\"label\"]\n",
        "    labels_test = test_df[\"label\"]\n",
        "\n",
        "    y_train = np.empty(len(labels_train), dtype=int)\n",
        "    for i, label in enumerate(labels_train):\n",
        "        y_train[i] = label_dict[label]\n",
        "\n",
        "    y_test = np.empty(len(labels_test), dtype=int)\n",
        "    for i, label in enumerate(labels_test):\n",
        "        y_test[i] = label_dict[label]\n",
        "\n",
        "    #執行one-hot encoding\n",
        "    Y_train = to_categorical(y_train, num_classes=len(label_dict))\n",
        "    Y_test = to_categorical(y_test, num_classes=len(label_dict))\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "\n",
        "audio_label_dict = {\"Cello\": 0,\"Clarinet\":1, \"Applause\":2}\n",
        "X_train, Y_train, X_test, Y_test = create_audio_dataset(train_df, test_df, train_data_dir, test_data_dir, audio_label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPfhwLG4jBtp"
      },
      "source": [
        "## 9-7 試著利用LSTN分類聲音"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MK9Yg-kNrJO"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Dropout,Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_lstm_model():\n",
        "  input_shape = (audio_length, 1)\n",
        "\n",
        "  #建立模型\n",
        "  model_lstm = Sequential()\n",
        "  model_lstm.add(LSTM(64, return_sequences=True, dropout=0.3 ,input_shape=input_shape))\n",
        "  model_lstm.add(LSTM(64, return_sequences=False, dropout=0.3))\n",
        "  model_lstm.add(Dense(units=len(audio_label_dict), activation=\"softmax\"))\n",
        "  model_lstm.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.001), metrics=[\"acc\"])\n",
        "  return model_lstm\n",
        "\n",
        "model_lstm = create_lstm_model()\n",
        "#顯示模型的構造\n",
        "model_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlwcdkcBNrLv"
      },
      "source": [
        "#開始學習\n",
        "history = model_lstm.fit(X_train, Y_train, batch_size=16, epochs=40, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0tuJWaMq4ee"
      },
      "source": [
        "#由於要耗費許多時間學習，建議大家拿掉下列程式碼的註解符號，直接載入這個模型的權重。\n",
        "#只要儲存了權重，執行第8節之後的程式就可以直接載入這個模型的權重，不需要重新學習\n",
        "\n",
        "#儲存模型的權重\n",
        "#model_lstm.save_weights('./saved_models/model_lstm_weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zpXDcC-_1C"
      },
      "source": [
        "#載入儲存的模型\n",
        "#model_lstm = create_lstm_model()\n",
        "#model_lstm.load_weights('./saved_models/model_lstm_weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hRWvYKwlxeW"
      },
      "source": [
        "## 9-8 試著評估LSTM的分類結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1pvtUCqm4k8"
      },
      "source": [
        "#開始預測\n",
        "predictions = model_lstm.predict(X_test, verbose=1)\n",
        "pred_labels = np.array([np.argmax(pred) for pred in predictions])\n",
        "actual_labels = np.array([audio_label_dict[lab] for lab in test_df[\"label\"]])\n",
        "\n",
        "#計算正確率\n",
        "tmp = actual_labels == pred_labels\n",
        "tmp.sum()/len(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHGIAhKmow-Q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#顯示評估函數與精確度的圖表\n",
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(history.history[\"loss\"], color=\"b\", label=\"Training Loss\")\n",
        "ax[0].plot(history.history[\"val_loss\"], color=\"g\", label=\"Validation Loss\")\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(history.history[\"acc\"], color=\"b\", label=\"Training Accuracy\")\n",
        "ax[1].plot(history.history[\"val_acc\"], color=\"g\", label=\"Validation Accuracy\")\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHCjss3lqjq9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "#建立混淆矩陣\n",
        "cf_matrix = confusion_matrix(actual_labels, pred_labels)\n",
        "\n",
        "plt.figure(figsize=(13,13))\n",
        "c = sns.heatmap(cf_matrix, annot=True, fmt=\"d\")\n",
        "\n",
        "#audio_label_dict = {\"Cello\": 0,\"Clarinet\":1, \"Applause\":2}\n",
        "audio_label_list = [\"Cello\", \"Clarinet\", \"Applause\"]\n",
        "c.set(xticklabels=audio_label_list, yticklabels=audio_label_list)\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLIFyMYHNsWc"
      },
      "source": [
        "## 9-9 試著利用CNN分類音樂"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arehnp7nHXTi"
      },
      "source": [
        "from tensorflow.keras.layers import Activation, Conv1D, MaxPooling1D, GlobalMaxPool1D,Dropout\n",
        "\n",
        "def create_cnn_model():\n",
        "  #建立模型\n",
        "  input_shape = (audio_length, 1)\n",
        "  model_cnn = Sequential()\n",
        "  model_cnn.add(Conv1D(filters=128, kernel_size=9, padding='valid', input_shape=input_shape, activation='relu'))\n",
        "  model_cnn.add(MaxPooling1D(pool_size=16))\n",
        "  model_cnn.add(Dropout(rate=0.2))\n",
        "  model_cnn.add(Conv1D(filters=64, kernel_size=3, padding='valid', activation='relu'))\n",
        "  model_cnn.add(GlobalMaxPool1D())\n",
        "  model_cnn.add(Dropout(rate=0.2))\n",
        "  model_cnn.add(Dense(len(audio_label_dict), activation=\"softmax\"))\n",
        "  model_cnn.compile(optimizer=Adam(0.0001), loss=\"categorical_crossentropy\", metrics=['acc'])\n",
        "  return model_cnn\n",
        "\n",
        "model_cnn = create_cnn_model()\n",
        "#顯示模型的構造\n",
        "model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsqUBflzJGWy"
      },
      "source": [
        "history = model_cnn.fit(X_train, Y_train, batch_size=16, epochs=50, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjokKOkK21mw"
      },
      "source": [
        "## 9-10 試著評估CNN的分類結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdA3Jw2q283d"
      },
      "source": [
        "#開始預測\n",
        "predictions = model_cnn.predict(X_test, verbose=1)\n",
        "pred_labels = np.array([np.argmax(pred) for pred in predictions])\n",
        "actual_labels = np.array([audio_label_dict[lab] for lab in test_df[\"label\"]])\n",
        "\n",
        "#計算正確率\n",
        "tmp = actual_labels == pred_labels\n",
        "tmp.sum()/len(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4uueWj3JG7z"
      },
      "source": [
        "#顯示評估函數與精確度的圖表\n",
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(history.history[\"loss\"], color=\"b\", label=\"Training Loss\")\n",
        "ax[0].plot(history.history[\"val_loss\"], color=\"g\", label=\"Validation Loss\")\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(history.history[\"acc\"], color=\"b\", label=\"Training Accuracy\")\n",
        "ax[1].plot(history.history[\"val_acc\"], color=\"g\", label=\"Validation Accuracy\")\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrS0GRAZJyLb"
      },
      "source": [
        "#建立混淆矩陣\n",
        "cf_matrix = confusion_matrix(actual_labels, pred_labels)\n",
        "\n",
        "plt.figure(figsize=(13,13))\n",
        "c = sns.heatmap(cf_matrix, annot=True, fmt=\"d\")\n",
        "\n",
        "#audio_label_dict = {\"Cello\": 0,\"Clarinet\":1, \"Applause\":2}\n",
        "audio_label_list = [\"Cello\", \"Clarinet\", \"Applause\"]\n",
        "c.set(xticklabels=audio_label_list, yticklabels=audio_label_list)\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}