{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Chapter10-1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UnzfHU4zdYYa"},"source":["# 第10章 了解深度學習的圖像處理與語言處理（1～4節）\n","在此要學習以深度學習偵測物體的演算法。\n","\n","若是在Google Colaboratory的環境下執行程式，請確定已將「硬體加速器」設定為「GPU」"]},{"cell_type":"code","metadata":{"id":"kqHgOuSaNA8u"},"source":["#Colaboratory環境的設定\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/MathProgramming/Chapter10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhWiI1G1CzJM"},"source":["#函式庫的設定\n","!pip install -q -r ./requirements1.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGLS2V67JR-f"},"source":["## 10-3 試著利用YOLO偵測物體"]},{"cell_type":"code","metadata":{"id":"g_sBaX_5nJBz"},"source":["#下載與解壓縮資料集。\n","#若無法下載請執行下列的程式碼。\n","!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n","!tar -xvf ./VOCtrainval_06-Nov-2007.tar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAKvqj2XnQj-"},"source":["#下載yolov3-tf2\n","!git clone https://github.com/zzh8829/yolov3-tf2.git ./yolov3_tf2\n","%cd ./yolov3_tf2\n","!git checkout c43df87d8582699aea8e9768b4ebe8d7fe1c6b4c\n","%cd ../"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5BjFMFnn7Za"},"source":["#下載學習完畢的YOLO模型\n","!wget https://pjreddie.com/media/files/yolov3-tiny.weights "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eByPqawwoVc7"},"source":["#將下載的YOLO模型轉換成keras可使用的格式\n","!python ./yolov3_tf2/convert.py --weights ./yolov3-tiny.weights --output  ./yolov3_tf2/checkpoints/yolov3-tiny.tf --tiny"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRSb05V_ryGC"},"source":["from PIL import Image\n","\n","#從下載的資料集之中挑一張的圖像顯示\n","Image.open(\"./VOCdevkit/VOC2007/JPEGImages/006626.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7-aAtnWryIi"},"source":["#顯示圖片的註解\n","annotation = open(\"./VOCdevkit/VOC2007/Annotations/006626.xml\").read()\n","print(annotation)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLnLblWMqm2p"},"source":["import xmltodict\n","import numpy as np\n","from tensorflow.keras.utils import Sequence\n","import math\n","import yolov3_tf2.yolov3_tf2.dataset as dataset\n","\n","yolo_max_boxes = 100\n","\n","#轉換註解資料的格式\n","def parse_annotation(annotation, class_map):\n","    label = []\n","    width = int(annotation['size']['width'])\n","    height = int(annotation['size']['height'])\n","    \n","    if 'object' in annotation:\n","        if type(annotation['object']) != list:\n","            tmp = [annotation['object']]\n","        else:\n","            tmp = annotation['object']\n","            \n","        for obj in tmp:\n","            _tmp = []\n","            _tmp.append(float(obj['bndbox']['xmin']) / width)\n","            _tmp.append(float(obj['bndbox']['ymin']) / height)\n","            _tmp.append(float(obj['bndbox']['xmax']) / width)\n","            _tmp.append(float(obj['bndbox']['ymax']) / height)\n","            _tmp.append(class_map[obj['name']])\n","            label.append(_tmp)\n","\n","    for _ in range(yolo_max_boxes - len(label)):\n","      label.append([0,0,0,0,0])\n","    return label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlyQ5j_PoXPa"},"source":["from yolov3_tf2.yolov3_tf2.dataset import transform_images\n","\n","#只載入學習所需的圖片的類別\n","class ImageDataSequence(Sequence):\n","    def __init__(self, file_name_list, batch_size,  anchors, anchor_masks, class_names, data_shape=(256,256,3)):\n","        \n","        #建立儲存類別名稱與對應數值的字典\n","        self.class_map = {name: idx for idx, name in enumerate(class_names)}\n","        self.file_name_list = file_name_list\n","\n","        self.image_file_name_list = [\"./VOCdevkit/VOC2007/JPEGImages/\"+image_path + \".jpg\" for image_path in self.file_name_list]\n","        self.annotation_file_name_list = ['./VOCdevkit/VOC2007/Annotations/' + image_path+ \".xml\" for image_path in self.file_name_list]\n","\n","        self.length = len(self.file_name_list)\n","        self.data_shape = data_shape\n","        self.batch_size = batch_size\n","        self.anchors = anchors\n","        self.anchor_masks = anchor_masks\n","\n","        self.labels_cache = [None for i in range(self.__len__())]\n","\n","    #每次自動呼叫此函數。只載入必要的圖片檔與對應的標籤。\n","    def __getitem__(self, idx):\n","        images = []\n","        labels = []\n","        \n","        #idx變數儲存了現在是第幾批次的資料、所以可根據此變數載入對應的資料\n","        for index in range(idx*self.batch_size, (idx+1)*self.batch_size):\n","\n","          #將註解轉換成可使用的標籤\n","          annotation = xmltodict.parse((open(self.annotation_file_name_list[index]).read()))\n","          label = parse_annotation(annotation[\"annotation\"], self.class_map)\n","          labels.append(label)\n","\n","          #載入與加工圖片\n","          img_raw = tf.image.decode_jpeg(open(self.image_file_name_list[index], 'rb').read(), channels=3)\n","          img = transform_images(img_raw, self.data_shape[0])\n","          images.append(img)\n","        \n","        #標籤也需要前置處理，但實在太耗費時間，所以載入之後，儲存為快取資料\n","        if self.labels_cache[idx] is None:\n","          labels = tf.convert_to_tensor(labels, tf.float32)\n","          labels = dataset.transform_targets(labels, self.anchors, self.anchor_masks, self.data_shape[0])\n","          self.labels_cache[idx] = labels\n","        else: \n","          labels = self.labels_cache[idx]\n","\n","        images = np.array(images)\n","        return images, labels\n","\n","    def __len__(self):\n","        return math.floor(len(self.file_name_list) / self.batch_size)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pT83GAyExapw"},"source":["from  yolov3_tf2.yolov3_tf2.models import  YoloV3Tiny, YoloLoss\n","from yolov3_tf2.yolov3_tf2.utils import freeze_all\n","import tensorflow as tf\n","\n","batch_size=16\n","data_shape=(416,416,3)\n","class_names =  [\"person\", \"bird\", \"cat\",\"cow\",\"dog\", \"horse\",\"sheep\", \"aeroplane\", \"bicycle\", \"boat\", \"bus\", \"car\", \"motorbike\", \"train\", \"bottle\", \"chair\", \"diningtable\", \"pottedplant\", \"sofa\", \"tvmonitor\"]\n","\n","anchors = np.array([(10, 14), (23, 27), (37, 58),\n","                              (81, 82), (135, 169),  (344, 319)],\n","                             np.float32) / data_shape[0]\n","anchor_masks = np.array([[3, 4, 5], [0, 1, 2]])\n","\n","# 載入於yolov3_tf2定義的tiny YOLO模型\n","model_pretrained = YoloV3Tiny(data_shape[0], training=True, classes=80)\n","model_pretrained.load_weights(\"./yolov3_tf2/checkpoints/yolov3-tiny.tf\").expect_partial()\n","\n","model = YoloV3Tiny(data_shape[0], training=True, classes=len(class_names))\n","#這裡只從學習完畢的模型取得非輸出層的權重\n","model.get_layer('yolo_darknet').set_weights(model_pretrained.get_layer('yolo_darknet').get_weights())\n","#不學習輸出層以外的層\n","freeze_all(model.get_layer('yolo_darknet'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uv8wOy-yJfO"},"source":["loss = [YoloLoss(anchors[mask], classes=len(class_names)) for mask in anchor_masks]\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=loss, run_eagerly=False)\n","\n","#輸出模型的構造\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K5xgUKjiyRSQ"},"source":["train_file_name_list = open(\"./VOCdevkit/VOC2007/ImageSets/Main/train.txt\").read().splitlines()\n","validation_file_name_list = open(\"./VOCdevkit/VOC2007/ImageSets/Main/val.txt\").read().splitlines()\n","\n","train_dataset = ImageDataSequence(train_file_name_list, batch_size, anchors, anchor_masks, class_names, data_shape=data_shape)\n","validation_dataset = ImageDataSequence(validation_file_name_list, batch_size, anchors, anchor_masks, class_names, data_shape=data_shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQrv-F_YyW6f"},"source":["history = model.fit(train_dataset, validation_data=validation_dataset, epochs=30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHdcPhz_yZXU"},"source":["#儲存學習所得的權重\n","model.save_weights('./saved_models/model_yolo_weights')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3OqkGbOW3c6i"},"source":["## 10-4 評估物體偵測處理的結果"]},{"cell_type":"code","metadata":{"id":"_Hp9rZ5q1Iay"},"source":["from absl import app, logging, flags\n","from absl.flags import FLAGS\n","app._run_init(['yolov3'], app.parse_flags_with_usage)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XizpUkI11IdK"},"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from yolov3_tf2.yolov3_tf2.utils import draw_outputs\n","\n","yolo_trained = YoloV3Tiny(classes=len(class_names))\n","#載入儲存的權重\n","yolo_trained.load_weights('./saved_models/model_yolo_weights').expect_partial()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smr62Jkw1Ifq"},"source":["img_file_name = \"./VOCdevkit/VOC2007/JPEGImages/\"+\"006626\" + \".jpg\"\n","\n","#載入圖片\n","img_raw = tf.image.decode_jpeg(open(img_file_name, 'rb').read(), channels=3)\n","img = transform_images(img_raw, data_shape[0])\n","img = np.expand_dims(img, 0)\n","\n","\n","#開始預測\n","boxes, scores, classes, nums = yolo_trained.predict(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKiCvBwC1Ih4"},"source":["img = img_raw.numpy()\n","\n","#將預測結果寫入圖片\n","img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n","\n","#顯示寫有預測結果的圖片\n","plt.figure(figsize=(10,10))\n","plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2bBDwf61Ip8"},"source":["#直接使用學習所得的權重\n","\n","FLAGS.yolo_iou_threshold = 0.5\n","FLAGS.yolo_score_threshold = 0.5\n","\n","yolo_class_names = [c.strip() for c in open(\"./yolov3_tf2/data/coco.names\").readlines()]\n","\n","yolo = YoloV3Tiny(classes=80)\n","#載入權重\n","yolo.load_weights(\"./yolov3_tf2/checkpoints/yolov3-tiny.tf\").expect_partial()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0_NTn0P_VWC"},"source":["img_file_name = \"./VOCdevkit/VOC2007/JPEGImages/\"+\"006626\" + \".jpg\"\n","\n","img_raw = tf.image.decode_jpeg(open(img_file_name, 'rb').read(), channels=3)\n","img = transform_images(img_raw, data_shape[0])\n","img = np.expand_dims(img, 0)\n","#開始預測\n","boxes, scores, classes, nums = yolo.predict(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rpFo8yPt_dte"},"source":["img = img_raw.numpy()\n","img = draw_outputs(img, (boxes, scores, classes, nums), yolo_class_names)\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(img)\n","plt.show()"],"execution_count":null,"outputs":[]}]}