{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter10-3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccwu0918/MathProgramming/blob/main/Chapter10/Chapter10-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lozOstEFZjwY"
      },
      "source": [
        "# 第10章 圖片、語言處理的深度學習全貌（8～10節）\n",
        "從這節開始要學習深度學習的自然語言處理。\n",
        "\n",
        "若是在Google Colaboratory的環境下執行程式，請確定已將「硬體加速器」設定為「GPU」"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUKKo31dLSIq"
      },
      "source": [
        "#Colaboratory環境的設定\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/MathProgramming/Chapter10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoIRAnPQZvEt"
      },
      "source": [
        "#函式庫的設定\n",
        "!pip install -q -r ./requirements3.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKcM6jRoZyXL"
      },
      "source": [
        "## 10-9 試著利用Bert分類文本"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnZo7PBbZsoA"
      },
      "source": [
        "import pandas as pd\n",
        "data_file='./spam.csv'\n",
        "df = pd.read_csv('./spam.csv')\n",
        "print(df[\"label\"].value_counts())\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GycwhFqbZ3tM"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import numpy as np\n",
        "tf.config.run_functions_eagerly(False)\n",
        "\n",
        "#載入執行事前處理的模組\n",
        "bert_preprocess = hub.load(\"https://tfhub.dev/tensorflow/bert_en_cased_preprocess/2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmQ1xHekaO4R"
      },
      "source": [
        "test_preprocessed = bert_preprocess([\"Hello World!\"])\n",
        "test_preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQFLpq0Pads0"
      },
      "source": [
        "#將七成的資料分割成學習專用資料，再讓剩下的三成資料當成驗證專用資料使用\n",
        "train_df = df[0: int(len(df)*0.7)]\n",
        "test_df = df[int(len(df)*0.7):]\n",
        "\n",
        "#利用前置處理模組處理字串\n",
        "X_train =  bert_preprocess(train_df[\"text\"])\n",
        "X_test = bert_preprocess(test_df[\"text\"])\n",
        "\n",
        "#對標籤(Spam與Ham)執行Onehot encoding\n",
        "Y_train = pd.get_dummies(train_df[\"label\"]).values.astype(np.float32)\n",
        "Y_test = pd.get_dummies(test_df[\"label\"]).values.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBzxczfOvnR6"
      },
      "source": [
        "#建立模型\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "\n",
        "#輸入值為input_word_ids, input_mask, input_type_ids這3個。\n",
        "inputs = dict(\n",
        "      input_word_ids=Input(shape=(None,), dtype=tf.int32),\n",
        "      input_mask=Input(shape=(None,), dtype=tf.int32),\n",
        "      input_type_ids=Input(shape=(None,), dtype=tf.int32))\n",
        "\n",
        "#從Tensorflow Hub載入Bert的模型\n",
        "outputs = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1\", trainable=True, name='bert_encoder')(inputs)\n",
        "outputs = outputs[\"pooled_output\"]\n",
        "outputs = Dropout(0.1)(outputs)\n",
        "#為了最終的輸出結果為2個（SpamとHam），在最後加上全連線層\n",
        "outputs = Dense(2, activation=\"softmax\", name='classifier')(outputs)\n",
        "model = Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk5ETHwea0P5"
      },
      "source": [
        "from official.nlp import optimization\n",
        "EPOCHS = 3\n",
        "num_train_steps =  len(train_df.index) * EPOCHS\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "#這次使用的Optimizer為AdamW\n",
        "optimizer = optimization.create_optimizer(init_lr=0.00003,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "#輸出模型的概要\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_93_NFpY2Abo"
      },
      "source": [
        "#開始學習\n",
        "hist = model.fit(X_train,Y_train,epochs=EPOCHS, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAgsbBbN3RRH"
      },
      "source": [
        "#由於學習很耗費時間，可執行下列的程式碼，直接儲存與載入模型的權重。\n",
        "#只要先儲存模型的權重，執行第10節以後的程式碼的時候，就能直接使用儲存的權重，模型也不需要重新學習。\n",
        "\n",
        "#儲存學習所得的權重\n",
        "#model.save_weights('./saved_models/model_bert_weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmxfpBQm3nh-"
      },
      "source": [
        "#載入權重\n",
        "#model.load_weights('./saved_models/model_bert_weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY2paknfs2YE"
      },
      "source": [
        "## 10-10 試著評估以Bert分類文本的結果\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9cmUX7bknF"
      },
      "source": [
        "#分類開始\n",
        "pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsCPvEgFjeEJ"
      },
      "source": [
        "pred_labels = np.array([np.argmax(p) for p in pred])\n",
        "actual_labels = np.array([np.argmax(t) for t in Y_test])\n",
        "tmp = actual_labels == pred_labels\n",
        "tmp.sum()/len(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVFgjp0obolD"
      },
      "source": [
        "#顯示混淆矩陣\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cf_matrix = confusion_matrix(actual_labels, pred_labels)\n",
        "\n",
        "c = sns.heatmap(cf_matrix, annot=True, fmt=\"d\")\n",
        "\n",
        "label_dict = {\"ham\": 0, \"spam\":1}\n",
        "c.set(xticklabels=label_dict, yticklabels=label_dict)\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iar0zkAMhGlz"
      },
      "source": [
        "#預測的文本\n",
        "print(\"預測: \" , pred_labels[0])\n",
        "print(test_df.iloc[0][\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6QYBSkQhUrw"
      },
      "source": [
        "print(\"預測: \" , pred_labels[3])\n",
        "print(test_df.iloc[3][\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}